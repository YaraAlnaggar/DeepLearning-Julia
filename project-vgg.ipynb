{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "You are required to make the foolowing functions after downloading the data from the above link:\n",
    "1. A function \"get_images\" to return the first 100 images from the folder: \"flowers-recognition/flowers/daisy/\"\n",
    "2. A function \"run_vgg\" that will run vgg over the 100 images that outputs from \"get_images\" and inside this\n",
    "function: record the number of mis-classified images given that any image will be considered as\n",
    "miclassified if the output class is not 985\n",
    "Notes\n",
    "1. you have to subtract 1 from the output class of vgg because classes start from 0 at imagenet)\n",
    "2. The misclassified result should be 18 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "] activate ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Images\n",
    "using Metalhead\n",
    "using Metalhead: classify\n",
    "using Flux, Flux.Data.MNIST, Statistics\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle\n",
    "using Base.Iterators: repeated, partition\n",
    "using Images\n",
    "using Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_images (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_images(dir,num)\n",
    "    images= []\n",
    "    for (root, dirs, files) in walkdir(dir)    \n",
    "        for file in files[1:num]\n",
    "            f_name=joinpath(root,file)\n",
    "            pic=load(f_name)\n",
    "            append!(images,[pic])\n",
    "        end\n",
    "    end\n",
    "    return images\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_vgg (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function run_vgg()\n",
    "    vgg=VGG19()\n",
    "    v=[]\n",
    "    c=0\n",
    "    images=get_images(\"flowers-recognition/flowers/daisy/\",100)\n",
    "    for pic in images\n",
    "        pred=classify(vgg,pic)\n",
    "        if pred!=\"daisy\"\n",
    "            c+=1\n",
    "        end\n",
    "    end\n",
    "    return c\n",
    "end\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: VGG19 not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: VGG19 not defined",
      "",
      "Stacktrace:",
      " [1] run_vgg() at ./In[14]:2",
      " [2] top-level scope at In[15]:1"
     ]
    }
   ],
   "source": [
    "mistakes=run_vgg()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Question [2]\n",
    "1. Make a chain named \"vgg_26\" to get the first 26 layers from the VGG as they are and add to them a Dense\n",
    "layer that will be responsible for classifiying two classes only and a softmax layer\n",
    "2. Make a function \"get_rose_sunflower\" to get the first 100 images from \"rose\" folder and the first 100\n",
    "images from \"sunflower\" folder. The output images will represent the two classes that we need to classiify\n",
    "now (instead of the 1000 classes that vgg knew before). Inside the function:\n",
    "let 20% of each set of images to be test data and the remaining to be training data\n",
    "Shuffle the resulting training data (that will be now a mix of some images of rose and some images of\n",
    "sunflower)\n",
    "It will output the shuffled training data(both x and y) and the testing data(both x and y)\n",
    "3. Train the chain you created at 1 using the training data that comes from function \"get_rose_sunflower\".\n",
    "Training iterations are 10 and the batch size at each iteration is the size of whole data\n",
    "4. Test the chain using the test data and record the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Chain(Conv((3, 3), 3=>64, NNlib.relu), Conv((3, 3), 64=>64, NNlib.relu), getfield(Metalhead, Symbol(\"##42#48\"))(), Conv((3, 3), 64=>128, NNlib.relu), Conv((3, 3), 128=>128, NNlib.relu), getfield(Metalhead, Symbol(\"##43#49\"))(), Conv((3, 3), 128=>256, NNlib.relu), Conv((3, 3), 256=>256, NNlib.relu), Conv((3, 3), 256=>256, NNlib.relu), Conv((3, 3), 256=>256, NNlib.relu), getfield(Metalhead, Symbol(\"##44#50\"))(), Conv((3, 3), 256=>512, NNlib.relu), Conv((3, 3), 512=>512, NNlib.relu), Conv((3, 3), 512=>512, NNlib.relu), Conv((3, 3), 512=>512, NNlib.relu), getfield(Metalhead, Symbol(\"##45#51\"))(), Conv((3, 3), 512=>512, NNlib.relu), Conv((3, 3), 512=>512, NNlib.relu), Conv((3, 3), 512=>512, NNlib.relu), Conv((3, 3), 512=>512, NNlib.relu), getfield(Metalhead, Symbol(\"##46#52\"))(), getfield(Metalhead, Symbol(\"##47#53\"))(), Dense(25088, 4096, NNlib.relu), Dropout{Float32}(0.5f0, false), Dense(4096, 4096, NNlib.relu), Dropout{Float32}(0.5f0, false)), Dense(4096, 2), NNlib.softmax)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_26 = Chain(\n",
    "    VGG19().layers[1:26],\n",
    "    Dense(4096,2),\n",
    "    softmax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_rose_sunflower (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_rose_sunflower()\n",
    "    rose_100_img= get_images(\"flowers-recognition/flowers/rose/\",100)\n",
    "    sunflower_100_img= get_images(\"flowers-recognition/flowers/sunflower/\",100)\n",
    "    rose_train, rose_test= rose_100_img[1:80],rose_100_img[81:100]\n",
    "    sunflower_train, sunflower_test= sunflower_100_img[1:80],sunflower_100_img[81:100]\n",
    "    \n",
    "    train_x,train_y = hcat(rose_train,sunflower_train),hcat(repeat([\"rose\"],80) , repeat([\"sunflower\"],80) )\n",
    "    test_x,test_y = vcat(rose_test,sunflower_test),vcat(repeat([\"rose\"],20) , repeat([\"sunflower\"],20) )\n",
    "    \n",
    "    index_shuff= shuffle(Vector(1:160))\n",
    "    train_shuff_x,train_shuff_y= train_x[index_shuff],train_y[index_shuff]\n",
    "    \n",
    "    #Preprocessing the dataset using metalhead preprocessing\n",
    "    train_shuff_x=[(Metalhead.preprocess(train_shuff_x[i])) for i in range(1,length=size(train_shuff_x,1))] \n",
    "    test_x=[(Metalhead.preprocess(test_x[i])) for i in range(1,length=size(test_x,1))] \n",
    "    return train_shuff_x,train_shuff_y,test_x,test_y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_VGG26 (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x, y) = crossentropy(vgg_26(x), y)\n",
    "accuracy(x, y) = mean(onecold(vgg_26(x)) .== onecold(y))\n",
    "\n",
    "function train_VGG26(X, Y, dataset,n)\n",
    "    evalcb = throttle(() -> @show(accuracy(X, Y)), 10)\n",
    "    opt = ADAM(params(vgg_26))\n",
    "    for i=1:n\n",
    "        Flux.train!(loss, dataset, opt, cb = evalcb)\n",
    "    end\n",
    "end\n",
    "\n",
    "function test_VGG26(X, Y)\n",
    "    accuracy(X, Y)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,train_y,test_x,test_y=get_rose_sunflower()\n",
    "train_y = onehotbatch(train_y, [\"rose\" , \"sunflower\"]);\n",
    "test_y = onehotbatch(test_y, [\"rose\" , \"sunflower\"]);\n",
    "\n",
    "train_x_all=train_x[1]\n",
    "for i=2:size(train_x,1)\n",
    "    train_x_all= cat(train_x_all,train_x[i]; dims=4)\n",
    "end\n",
    "\n",
    "\n",
    "test_x_all= test_x[1]\n",
    "for i=2:size(test_x,1)\n",
    "    test_x_all= cat(test_x_all,test_x[i]; dims=4)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_x_all = convert(Array{Float64,4}, train_x_all);\n",
    "batches=[(train_x_all[:,:,:,i],train_y[:,i]) for i in partition(1:size(train_x_all,4),10)] ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(X, Y) = 0.5875\n",
      "accuracy(X, Y) = 0.8125\n",
      "accuracy(X, Y) = 0.91875\n",
      "accuracy(X, Y) = 0.90625\n",
      "accuracy(X, Y) = 0.9\n",
      "accuracy(X, Y) = 0.9375\n"
     ]
    }
   ],
   "source": [
    "train_VGG26(train_x_all,train_y,batches,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_VGG26(test_x_all,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Make a new chain called \"vgg_24\" that takes the first 24 layers from the VGG as they are. and add to them\n",
    "3 layers: Dense layer, and Another Dense layer to classify the two classes and a softmax layer.\n",
    "2. In this chain, Initlize the w and b of the first Dense that youy just created by the optimal weights that VGG\n",
    "reached in it before.\n",
    "\n",
    "Note\n",
    "This Dense layer is called in VGG \"fc7\" and you can get the optimal weights from :\n",
    "Metalhead.weights()..Search for this on the github of Metahead and you can find an example to\n",
    "run over VGG.\n",
    "Then get the w and b of the layer called fc7 and initlize your first dense with it to start our\n",
    "learning from these values\n",
    "\n",
    "3.Train and Test vgg_24 in same way as in question 2 and record the testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `/home/jrun/.julia/registries/JuliaPro`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://pkg.juliacomputing.com/registry/JuliaPro`\n",
      "\u001b[2K\u001b[?25h[1mFetching:\u001b[22m\u001b[39m [========================================>]  100.0 %.0 %13.7 %>                             ]  27.4 %                  ]  54.7 % [============================>            ]  68.4 % ]  95.3 %\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "Pkg.add(\"BSON\") \n",
    "using BSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Symbol,Any} with 38 entries:\n",
       "  :conv4_2_w_0 => Float32[-0.00605492 -0.00096373 0.000626743; 0.00679103 0.009…\n",
       "  :conv3_3_w_0 => Float32[-0.000198241 -0.000861549 -0.00059339; 0.00153241 -0.…\n",
       "  :fc6_w_0     => Float32[0.000740605 -9.02351e-5 … 0.000489794 -0.000968067; -…\n",
       "  :fc8_w_0     => Float32[0.0117621 -0.00695795 … -0.00535216 0.0103952; -0.011…\n",
       "  :conv4_3_b_0 => Float32[0.00169088, 0.043703, 0.0566955, 0.0205713, 0.0076408…\n",
       "  :conv1_2_w_0 => Float32[0.148688 0.170782 -0.0197718; 0.181252 -0.0287904 -0.…\n",
       "  :conv3_4_w_0 => Float32[-0.0145519 -0.0260602 -0.0111239; -0.00908116 -0.0275…\n",
       "  :conv2_2_w_0 => Float32[-0.000591473 -0.00272857 -0.00527541; 0.00139092 0.00…\n",
       "  :conv2_2_b_0 => Float32[-0.0764114, -0.110066, -0.144156, 0.0385552, 0.258943…\n",
       "  :conv3_3_b_0 => Float32[0.0205515, -0.0192079, 0.0514344, 0.0547953, 0.094897…\n",
       "  :conv2_1_b_0 => Float32[-0.0426487, 0.0790341, -0.0259495, 0.099568, 0.113474…\n",
       "  :conv4_1_w_0 => Float32[0.0258524 0.0609968 0.0256101; -0.00310215 -0.0016468…\n",
       "  :fc6_b_0     => Float32[-0.211796, 0.136735, -0.264046, -0.270283, -0.217785,…\n",
       "  :fc7_b_0     => Float32[0.633823, 0.457725, 0.57202, 0.371374, 0.563893, 0.42…\n",
       "  :conv1_1_w_0 => Float32[0.341195 0.232159 -0.0726092; 0.339992 0.0897821 -0.2…\n",
       "  :conv4_3_w_0 => Float32[0.0224884 0.00958263 -0.00786132; 0.0394638 0.0211056…\n",
       "  :conv1_2_b_0 => Float32[-0.292965, 0.339774, 0.159743, 0.0413218, 0.776448, 0…\n",
       "  :conv4_2_b_0 => Float32[0.00436518, -0.0094778, -0.00375432, 0.0194299, -0.01…\n",
       "  :conv4_4_w_0 => Float32[0.0126708 0.0157267 0.0163364; 0.00733232 0.0141943 0…\n",
       "  :conv3_1_b_0 => Float32[0.0319589, -0.00308649, 0.0262481, 0.033408, -0.16205…\n",
       "  :conv5_3_b_0 => Float32[-0.0102901, 0.148979, 0.247273, -0.0415912, -0.049339…\n",
       "  :conv4_4_b_0 => Float32[0.0418459, -0.0647015, 0.0147138, -0.0351887, -0.0006…\n",
       "  :conv5_4_b_0 => Float32[0.722275, -0.485727, 0.405659, 0.141624, 0.492161, -0…\n",
       "  :conv5_2_w_0 => Float32[-0.0112246 0.0112363 0.0155007; -0.0214444 0.00341689…\n",
       "  :conv3_4_b_0 => Float32[0.0842536, 0.0619479, 0.0269964, -0.000544604, -0.000…\n",
       "  ⋮            => ⋮"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws=BSON.load(\"vgg19.bson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096-element Array{Float32,1}:\n",
       " 0.63382286\n",
       " 0.4577255 \n",
       " 0.57202035\n",
       " 0.37137407\n",
       " 0.5638934 \n",
       " 0.42521483\n",
       " 0.24163638\n",
       " 0.18872565\n",
       " 0.6788014 \n",
       " 0.3629831 \n",
       " 0.21210502\n",
       " 0.6111959 \n",
       " 0.41938317\n",
       " ⋮         \n",
       " 0.51462954\n",
       " 0.5900871 \n",
       " 0.47841918\n",
       " 0.29396743\n",
       " 0.4824054 \n",
       " 0.3367087 \n",
       " 0.46477816\n",
       " 0.5200556 \n",
       " 0.09609667\n",
       " 0.5036738 \n",
       " 0.41717583\n",
       " 0.6895467 "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_f7_w=ws[:fc7_w_0]'\n",
    "dense_f7_b=ws[:fc7_b_0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my_init_b (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dense_layer_w= params(m)[3]\n",
    "# dense_layer_b= params(m)[4]\n",
    "\n",
    "# function my_init_w(out,in_n)\n",
    "#     Tracker.data(dense_layer_w)\n",
    "# end\n",
    "\n",
    "function my_init_w(out,in_n)\n",
    "    return dense_f7_w\n",
    "end\n",
    "\n",
    "function my_init_b(b)\n",
    "    return dense_f7_b\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Chain(Conv((3, 3), 3=>64, NNlib.relu), Conv((3, 3), 64=>64, NNlib.relu), getfield(Metalhead, Symbol(\"##42#48\"))(), Conv((3, 3), 64=>128, NNlib.relu), Conv((3, 3), 128=>128, NNlib.relu), getfield(Metalhead, Symbol(\"##43#49\"))(), Conv((3, 3), 128=>256, NNlib.relu), Conv((3, 3), 256=>256, NNlib.relu), Conv((3, 3), 256=>256, NNlib.relu), Conv((3, 3), 256=>256, NNlib.relu), getfield(Metalhead, Symbol(\"##44#50\"))(), Conv((3, 3), 256=>512, NNlib.relu), Conv((3, 3), 512=>512, NNlib.relu), Conv((3, 3), 512=>512, NNlib.relu), Conv((3, 3), 512=>512, NNlib.relu), getfield(Metalhead, Symbol(\"##45#51\"))(), Conv((3, 3), 512=>512, NNlib.relu), Conv((3, 3), 512=>512, NNlib.relu), Conv((3, 3), 512=>512, NNlib.relu), Conv((3, 3), 512=>512, NNlib.relu), getfield(Metalhead, Symbol(\"##46#52\"))(), getfield(Metalhead, Symbol(\"##47#53\"))(), Dense(25088, 4096, NNlib.relu), Dropout{Float32}(0.5f0, false)), Dense(4096, 4096, NNlib.relu), Dense(4096, 2), NNlib.softmax)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_24 = Chain(\n",
    "    VGG19().layers[1:24],\n",
    "    Dense(4096, 4096, relu, initW= my_init_w, initb= my_init_b),\n",
    "    Dense(4096, 2),\n",
    "    softmax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_VGG24 (generic function with 1 method)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x, y) = crossentropy(vgg_24(x), y)\n",
    "accuracy(x, y) = mean(onecold(vgg_24(x)) .== onecold(y))\n",
    "\n",
    "function train_VGG24(X, Y, dataset,n)\n",
    "    evalcb = throttle(() -> @show(accuracy(X, Y)), 10)\n",
    "    opt = ADAM(params(vgg_24))\n",
    "    for i=1:n\n",
    "        Flux.train!(loss, dataset, opt, cb = evalcb)\n",
    "    end\n",
    "end\n",
    "\n",
    "function test_VGG24(X, Y)\n",
    "    accuracy(X, Y)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_x_all = convert(Array{Float64,4}, train_x_all);\n",
    "batches=[(train_x_all[:,:,:,i],train_y[:,i]) for i in partition(1:size(train_x_all,4),10)] ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(X, Y) = 0.50625\n",
      "accuracy(X, Y) = 0.825\n",
      "accuracy(X, Y) = 0.81875\n",
      "accuracy(X, Y) = 0.9125\n",
      "accuracy(X, Y) = 0.84375\n",
      "accuracy(X, Y) = 0.975\n"
     ]
    }
   ],
   "source": [
    "train_VGG24(train_x_all,train_y,batches,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_VGG24(test_x_all,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Any,1}:\n",
       " Flux.Tracker.TrackedReal{Float32}[NaN (tracked) NaN (tracked) … NaN (tracked) NaN (tracked); NaN (tracked) NaN (tracked) … NaN (tracked) NaN (tracked); … ; NaN (tracked) NaN (tracked) … NaN (tracked) NaN (tracked); NaN (tracked) NaN (tracked) … NaN (tracked) NaN (tracked)]                                                               \n",
       " Flux.Tracker.TrackedReal{Float32}[NaN (tracked), NaN (tracked), NaN (tracked), NaN (tracked), NaN (tracked), NaN (tracked), NaN (tracked), NaN (tracked), NaN (tracked), NaN (tracked)  …  NaN (tracked), NaN (tracked), NaN (tracked), NaN (tracked), NaN (tracked), NaN (tracked), NaN (tracked), NaN (tracked), NaN (tracked), NaN (tracked)]\n",
       " Flux.Tracker.TrackedReal{Float64}[NaN (tracked) NaN (tracked) … NaN (tracked) NaN (tracked); NaN (tracked) NaN (tracked) … NaN (tracked) NaN (tracked)]                                                                                                                                                                                         \n",
       " Flux.Tracker.TrackedReal{Float64}[NaN (tracked), NaN (tracked)]                                                                                                                                                                                                                                                                                 "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params(vgg_24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.Now, make a change in vgg_24 at Q3.2 by adding the following: initlitize the w and b of the last Dense (before\n",
    "the softmax) with the optimal weights that you reached at question 2 from vgg_26\n",
    "5.Train and Test again and show if there is an improvement in the training time and in the final testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my_last_dense_b (generic function with 2 methods)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_layer_w= params(vgg_26)[1]\n",
    "dense_layer_b= params(vgg_26)[2]\n",
    "\n",
    "function my_last_dense_w(out,in_n)\n",
    "    Tracker.data(dense_layer_w)\n",
    "end\n",
    "\n",
    "function my_last_dense_b(b)\n",
    "    Tracker.data(dense_layer_b)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Chain(Conv((3, 3), 3=>64, NNlib.relu), Conv((3, 3), 64=>64, NNlib.relu), getfield(Metalhead, Symbol(\"##42#48\"))(), Conv((3, 3), 64=>128, NNlib.relu), Conv((3, 3), 128=>128, NNlib.relu), getfield(Metalhead, Symbol(\"##43#49\"))(), Conv((3, 3), 128=>256, NNlib.relu), Conv((3, 3), 256=>256, NNlib.relu), Conv((3, 3), 256=>256, NNlib.relu), Conv((3, 3), 256=>256, NNlib.relu), getfield(Metalhead, Symbol(\"##44#50\"))(), Conv((3, 3), 256=>512, NNlib.relu), Conv((3, 3), 512=>512, NNlib.relu), Conv((3, 3), 512=>512, NNlib.relu), Conv((3, 3), 512=>512, NNlib.relu), getfield(Metalhead, Symbol(\"##45#51\"))(), Conv((3, 3), 512=>512, NNlib.relu), Conv((3, 3), 512=>512, NNlib.relu), Conv((3, 3), 512=>512, NNlib.relu), Conv((3, 3), 512=>512, NNlib.relu), getfield(Metalhead, Symbol(\"##46#52\"))(), getfield(Metalhead, Symbol(\"##47#53\"))(), Dense(25088, 4096, NNlib.relu), Dropout{Float32}(0.5f0, false)), Dense(4096, 4096, NNlib.relu), Dense(4096, 2), NNlib.softmax)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_24_2 = Chain(\n",
    "    VGG19().layers[1:24],\n",
    "    Dense(4096, 4096,relu, initW= my_init_w, initb= my_init_b),\n",
    "    Dense(4096, 2, initW= my_last_dense_w, initb= my_last_dense_b),\n",
    "    softmax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_VGG24_2 (generic function with 1 method)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x, y) = crossentropy(vgg_24_2(x), y)\n",
    "accuracy(x, y) = mean(onecold(vgg_24_2(x)) .== onecold(y))\n",
    "\n",
    "function train_VGG24_2(X, Y, dataset,n)\n",
    "    evalcb = throttle(() -> @show(accuracy(X, Y)), 10)\n",
    "    opt = ADAM(params(vgg_24_2))\n",
    "    for i=1:n\n",
    "        Flux.train!(loss, dataset, opt, cb = evalcb)\n",
    "    end\n",
    "end\n",
    "\n",
    "function test_VGG24_2(X, Y)\n",
    "    accuracy(X, Y)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(X, Y) = 0.5\n",
      "accuracy(X, Y) = 0.80625\n",
      "accuracy(X, Y) = 0.9\n",
      "accuracy(X, Y) = 0.95\n",
      "accuracy(X, Y) = 0.9125\n",
      "accuracy(X, Y) = 0.9625\n"
     ]
    }
   ],
   "source": [
    "train_VGG24_2(train_x_all,train_y,batches,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_VGG24(test_x_all,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
